
catalog:

  qwen2.5-coder-1.5b-vllm-gpu:
    enabled: false
    features: ["TextGeneration"]
    url: "hf://Qwen/Qwen2.5-Coder-1.5B-Instruct"
    engine: VLLM
    env:
      VLLM_ATTENTION_BACKEND: FLASHINFER
    args:
    - --max-model-len=2048
    - --max-num-seqs=16
    - --quantization=fp8
    - --kv-cache-dtype=fp8
    minReplicas: 1
    resourceProfile: nvidia-gpu


  deepseek-r1-distill-qwen-1.5b-vllm-gpu:
    enabled: true
    features: ["TextGeneration"]
    url: "hf://deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B"
    engine: VLLM
    env:
      VLLM_USE_V1: "1"
    args:
    - --max-model-len=2048
    - --max-num-batched-token=2048
    - --max-num-seqs=8
    resourceProfile: nvidia-gpu

