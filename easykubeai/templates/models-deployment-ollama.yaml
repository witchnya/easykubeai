{{- range $serveName, $model := .Values.catalog }}
  {{- if $model.enabled }}
  {{- if eq $model.engine "OLlama" }}
    {{- $modelName := (trimPrefix "ollama://" $model.url) }}
    {{- $rpName := $model.resourceProfile | default "cpu" }}
    {{- $rp := index $.Values.resourceProfiles $rpName }}
    {{- $rcn := get $rp "runtimeClassName" }}
    {{- $mountPath := "/model" }}

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: model-deploy-{{ regexReplaceAll "[^a-zA-Z0-9-]" (lower $serveName) "-" }}
  labels:
    app: "model-{{ $serveName }}"
    model: "{{ regexReplaceAll "[^a-zA-Z0-9-.]" $modelName "-" }}"
  annotations:
    resourceProfile: {{ $rpName }}
spec:
  replicas: {{ $model.replicas | default 1 }}

  selector:
    matchLabels:
      app: "model-{{ $serveName }}"
      model: "{{ regexReplaceAll "[^a-zA-Z0-9-.]" $modelName "-" }}"
  template:
    metadata:
      labels:
        app: "model-{{ $serveName }}"
        model: "{{ regexReplaceAll "[^a-zA-Z0-9-.]" $modelName "-" }}"
    spec:
      {{- with $.Values.imagePullSecrets }}
      imagePullSecrets:
        {{- toYaml . | nindent 8 }}
      {{- end }}

      {{- with $rcn }}
      runtimeClassName: {{ . }}
      {{- end }}

      initContainers:
      - name: ollama-init
        image: {{ $.Values.modelServers.OLlama.images.default }}
        imagePullPolicy: {{ default $.Values.modelServers.OLlama.imagePullPolicy "IfNotPresent" }} 
        env:
        - name: OLLAMA_MODELS
          value: /model
        command:
        - /bin/sh
        - -c
        - |

          /bin/ollama serve &
          echo "# Waiting for Ollama server to start..."
          sleep 10

          # Pull the model and ensure it downloads successfully
          echo "# Pulling model ..."
          if ! /bin/ollama pull {{ $modelName }}; then
              echo "Failed to pull model"
              exit 1
          fi
          
          # Verify the model files exist
          echo "# Verifying model files..."
          ls -R /model
          if [ ! -d "/model/blobs" ] || [ ! -d "/model/manifests" ]; then
              echo "Model directories not found"
              exit 1
          fi
          
          echo "# Model setup completed successfully"
          ls -la /model/manifests/registry.ollama.ai/library/

          {{- if eq $rcn "nvidia" }}
          set -x
          nvidia-smi
          {{- end }}

        resources:
          limits:
            cpu: {{ ($rp).limits.cpu }}
            memory: {{ ($rp).limits.memory }}  
            
        volumeMounts:
        {{- if eq $.Values.modelCache.mode "pvc" }}
        - name: models-volume
          mountPath: {{ $mountPath }}
        {{- else if eq $.Values.modelCache.mode "host" }}
        - name: host-path
          mountPath: {{ $mountPath }}
        {{- end }}

      containers:
      - name: ollama-server
        image: {{ $.Values.modelServers.OLlama.images.default }}
        imagePullPolicy: {{ default $.Values.modelServers.OLlama.imagePullPolicy "IfNotPresent" }} 
        env:
          - name: OLLAMA_HOST
            value: 0.0.0.0:8000
          - name: OLLAMA_KEEP_ALIVE
            value: 999999h
          - name: OLLAMA_MODELS
            value: /model
        livenessProbe:
          failureThreshold: 3
          httpGet:
            path: /
            port: http
            scheme: HTTP
          initialDelaySeconds: 900
          periodSeconds: 30
          successThreshold: 1
          timeoutSeconds: 3
        ports:
        - containerPort: 8000
          name: http
          protocol: TCP
        readinessProbe:
          failureThreshold: 3
          httpGet:
            path: /
            port: http
            scheme: HTTP
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 2

        resources:
          # $model 의 resourceProfile 에서 가져온 값은 프로파일명 
          limits:
            cpu: {{ ($rp).limits.cpu }}
            memory: {{ ($rp).limits.memory }}  

        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          readOnlyRootFilesystem: false
          runAsUser: 0
        startupProbe:
          exec:
            command:
            - bash
            - -c
            - /bin/ollama pull {{ $modelName }} && /bin/ollama cp {{ $modelName }} {{ $serveName }} && /bin/ollama run {{ $serveName }} hi
          failureThreshold: 10
          initialDelaySeconds: 1
          periodSeconds: 3
          successThreshold: 1
          timeoutSeconds: 10800
        terminationMessagePath: /dev/termination-log
        terminationMessagePolicy: File
        volumeMounts:
        - name: dshm
          mountPath: /dev/shm
        {{- if eq $.Values.modelCache.mode "pvc" }}
        - name: models-volume
          mountPath: {{ $mountPath }}
        {{- else if eq $.Values.modelCache.mode "host" }}
        - name: host-path
          mountPath: {{ $mountPath }}
        {{- end }}

      terminationGracePeriodSeconds: 30

      volumes:
      - name: dshm
        emptyDir:
          medium: Memory
      {{- if eq $.Values.modelCache.mode "pvc" }}
      - name: models-volume
        persistentVolumeClaim:
          claimName: model-pvc-{{ regexReplaceAll "[^a-zA-Z0-9-]" (lower $modelName) "-" }}
      {{- else if eq $.Values.modelCache.mode "host" }}
      - name: host-path
        hostPath: 
          path: {{ $.Values.modelCache.host.hostPath }}
          type: Directory
      {{- end }}
      
     {{- with $model.nodeSelector }}
      nodeSelector:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      {{- with $model.affinity }}
      affinity:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      {{- with $model.tolerations }}
      tolerations:
        {{- toYaml . | nindent 8 }}
      {{- end }}

{{- end }}
{{- end }}
{{- end }}