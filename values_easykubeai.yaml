imagePullSecrets:
  #- name: my-registry-secret


###############################################################################
modelCache:
  persistence:
    storageClassName: "local-path"
    size: "10Gi"
    accessModes:
      - "ReadWriteOnce"
      #- "ReadWriteMany"
    annotations:
      "helm.sh/resource-policy": "keep"
      "kubernetes.io/pvc-protection": "true"


###############################################################################
secrets:
  huggingface:
    create: false
    token: ""


###############################################################################
modelServers:
  VLLM:
    images:
      default: "vllm/vllm-openai:v0.8.3"
  OLlama:
    images:
      default: "ollama/ollama:latest"


###############################################################################
resourceProfiles:
  cpu:
    requests:
      cpu: 2
      # TODO: Consider making this a ratio that is more common on cloud machines
      # such as 1:4 CPU:Mem. NOTE: This might need to be adjusted for local clusters.
      memory: "8Gi"
      # TODO: Consider adding eph storage requests/limits.
      # Perhaps this is just needed for GKE Autopilot which defaults
      # to 1Gi for CPU-only.
      # ephemeral-storage: "2Gi"
    limits:
      cpu: 12
      memory: "24Gi"
  
  nvidia-gpu:
    runtimeClassName: "nvidia"
    requests:
      nvidia.com/gpu: "1"
      cpu: 2
      memory: "4Gi"
    limits:
      nvidia.com/gpu: "1"
      cpu: 6
      memory: "12Gi"
    # tolerations:
    #   - key: "nvidia.com/gpu"
    #     operator: "Equal"
    #     value: "present"
    #     effect: "NoSchedule"
    # nodeSelector:
    #   nvidia.com/gpu.family: "ampere"
    #   nvidia.com/gpu.memory: "81614088"



###############################################################################
catalog:

  gemma3-1b-ollama-cpu:
    enabled: false

  gemma3-1b-ollama-gpu:
    enabled: true

  deepseek-r1-distill-qwen-1.5b-vllm-gpu:
    enabled: false

  qwen2.5-coder-1.5b-vllm-gpu:
    enabled: false

  qwen3-1.7b-vllm-gpu:
    enabled: false

  qwen3-4b-instruct-2507-vllm-gpu:
    enabled: false

###############################################################################
